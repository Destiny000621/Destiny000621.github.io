---
title: Hybrid Training for Enhanced Multi-task Generalization in Multi-agent Reinforcement Learning
summary: With the potential to solve complicated real-world problems, cooperative Multi-Agent Reinforcement Learning(MARL) has drawn tremendous attention recently. Since most MARL methods learn policies online in a single task using simulating environments, there exist two problems when contemplating its deployment in real-world robotic scenarios. Firstly, online reinforcement learning agents demonstrate sample inefficiency, necessitating billions of environmental interactions to attain optimal performance. Such a magnitude of sample interaction is not merely impractical but often unfeasible for the majority of real-world robotic applications. Secondly, a limited number of existing MARL algorithms can adapt to multiple tasks with varying agents and targets. In response to these challenges, this study proposes a novel MARL algorithm using both offline and online data. This integration aims to enhance sample efficiency and overall performance. We hypothesize that this approach will surpass the performance boundaries imposed by existing datasets and address pertinent issues such as distribution shift and out-of-distribution challenges.
tags:
  - Reinforcement Learning
date: '2024-08-24T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: 'https://arxiv.org/abs/2408.13567'

image:
  caption: Photo by rawpixel on Unsplash
  focal_point: Smart

url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
---
